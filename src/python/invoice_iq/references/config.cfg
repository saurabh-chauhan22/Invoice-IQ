[nlp]
lang = "en"
pipeline = ["ner"]
batch_size = 256

[training]
seed = 128
dropout = 0.2
max_epochs = 100
gpu_allocator = "pytorch"

[training.optimizer]
@optimizers = "Adam.v1"
learn_rate = 0.001

[training.batcher]
@batchers = "spacy.batch_by_words.v1"
discard_oversize = false
tolerance = 0.2

[paths]
train = "train.spacy"
dev = "test.spacy"

[components]

[components.ner]
factory = "ner"

[initialize]
vectors = null



# [nlp]
# lang = "en"
# pipeline = ["tok2vec","ner","parser"]
# batch_size = 128


# [paths]
# train = "train.spacy"
# dev = "test.spacy"

# [components]

# [components.tok2vec]
# factory = "tok2vec"

# [components.tok2vec.model]
# @architectures = "spacy.Tok2Vec.v2"

# [components.tok2vec.model.embed]
# @architectures = "spacy.MultiHashEmbed.v2"
# width = ${components.tok2vec.model.encode.width}
# attrs = ["NORM", "PREFIX", "SUFFIX", "SHAPE", "LOWER","IS_ALPHA","IS_DIGIT"]
# rows = [5000, 1000, 2500, 2500,5000,5000,5000]
# include_static_vectors = true

# [components.tok2vec.model.encode]
# @architectures = "spacy.MaxoutWindowEncoder.v2"
# width = 512
# depth = 8
# window_size = 1
# maxout_pieces = 3

# [components.parser]
# factory = "parser"

# [components.parser.model]
# @architectures = "spacy.TransitionBasedParser.v2"
# state_type = "parser"
# extra_state_tokens = false
# hidden_width = 256
# maxout_pieces = 4
# use_upper = true
# nO = null

# [components.parser.model.tok2vec]
# @architectures = "spacy.Tok2VecListener.v1"
# width = ${components.tok2vec.model.encode.width}

# [components.ner]
# factory = "ner"

# [components.ner.model]
# @architectures = "spacy.TransitionBasedParser.v2"
# state_type = "ner"
# extra_state_tokens = false
# hidden_width = 64
# maxout_pieces = 2
# use_upper = true
# nO = null

# [components.ner.model.tok2vec]
# @architectures = "spacy.Tok2VecListener.v1"
# width = ${components.tok2vec.model.encode.width}

# [corpora]

# [corpora.train]
# @readers = "spacy.Corpus.v1"
# path = ${paths.train}
# max_length = 0

# [corpora.dev]
# @readers = "spacy.Corpus.v1"
# path = ${paths.dev}
# max_length = 0

# [training]
# seed = 42
# dropout = 0.2
# max_epochs = 30
# gpu_allocator = null
# dev_corpus = "corpora.dev"
# train_corpus = "corpora.train"

# [training.optimizer]
# @optimizers = "Adam.v1"

# [training.batcher]
# @batchers = "spacy.batch_by_words.v1"
# discard_oversize = false
# tolerance = 0.2

# [training.batcher.size]
# @schedules = "compounding.v1"
# start = 100
# stop = 1000
# compound = 1.001

# [initialize]
# vectors = "en_core_web_lg" 
# init_tok2vec = null